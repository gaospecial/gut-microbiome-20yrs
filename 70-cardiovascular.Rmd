# 肠道菌群与心血管疾病 {#CVD}

方法：

- 从《热心肠日报》中搜索“菌群”和“心血管”，找出对应短科普，提取关键词，获取大体脉络。
- 利用关键词到 WOS 中搜索，查看研究趋势。
- 利用 WOS 搜索结果，从中找出高被引的论文出来。

## 热心肠日报相关资源

```{r}
db_cache <- "E:/Spring_Work/Corporate_Bussiness/C40_Data/cache/"
papers <- read_rds(paste0(db_cache,"papers.RDS")) %>% as_tibble() %>%  mutate_all(iconv,from="utf-8",sub=" ")
fragments <- read_rds(paste0(db_cache,"fragments.RDS")) %>% as_tibble() %>%  mutate_all(iconv,from="utf-8",sub=" ")

real_paper <- papers %>% 
  filter(status==3 & classify=="audit" & journal_id=="1") %>%
  select(uuid,title,share_title,summary,remark,fragment_id) %>% 
  left_join(fragments %>% rename("fragment_id"=id) %>% select(-uuid,-title,-remark))
```

```{r}
# 心血管相关文献
search_results <- real_paper %>% 
  mutate(content=paste(share_title,remark,summary,sep = ";")) %>% 
  filter(str_detect(content,"心血管")) %>%
  filter(str_detect(content,"菌群"))
```

```{r}
# 输出 search_results
search_results <- search_results %>% 
  mutate(pub_year = year(as.Date(time)),
         impact_factor = as.numeric(impact_factor),
         img_url=paste0("https://pics-xldkp-com.oss-cn-qingdao.aliyuncs.com/",summary_image),
         link = mrgut_permanent_link(uuid = uuid,title=share_title,alt = "查看原文")) %>%
  arrange(desc(pub_year),desc(impact_factor)) 

years <- unique(search_results$pub_year) %>% as.character()
```


```{r eval=F}

# 生成热心肠日报中“心血管疾病”相关文献的合集。
success <- lapply(years, function(year){
  paste0("## ",year) %>% cat()
  cat("\n\n")
  df <- search_results %>% filter(pub_year==year)
  for (i in 1:nrow(df)){

    paste0("### ", df[i,"link"]) %>% cat()
    cat("\n\n")
    
    paste0(df[i,"periodical"]," [IF=",df[i,"impact_factor"],"]") %>% cat()
    cat("\n\n")         
   
    if (!is.na(df[i,"img_url"])){
      paste0("![](",df[i,"img_url"],")") %>% cat()
      cat("\n\n")
    }

    paste0("[主编评语]：",df[i,"remark"]) %>% cat()
    cat("\n\n")
    
    paste0(df[i,"summary"]) %>% cat()
    cat("\n\n")
  }
  
})
```

日报中文关键词词云


```{r}

chinese_keywords <- mrgut_word_freq(search_results$content) %>% 
  mutate(word_segmentation=as.character(word_segmentation)) %>%
  filter(!str_detect(word_segmentation,"菌群|综述|一篇|值得|多种|近期|发表|来自|团队|特别|有助于|文章|推荐|鉴定|最新|Nature|导致|程度|潜在|分析|介导|因素|一项|特定|Reviews|关注")) %>%
  filter(nchar(word_segmentation)>1)
```


```{r }
wordcloud2(chinese_keywords,fontFamily = "微软雅黑")

```

日报英文关键词词云

```{r}
additional_stopwords <- "yet may one two use thus like work part either show but never non need among also however study" %>%
  strsplit(" ") %>% unlist()
english_keywords <- mrgut_word_freq(tolower(search_results$en_summary),lang = "English") %>%
  mutate(word_segmentation=as.character(word_segmentation)) %>%
  filter(!word_segmentation %in% c(letters,seq(0,9),additional_stopwords)) %>%
  filter(!str_detect(word_segmentation,regex(pattern = paste0(search_keywords,collapse = "|"),ignore_case = T)))


wordcloud2(english_keywords,fontFamily = "微软雅黑")

```

## 把日报数据可视化

```{r}
# 日报期刊源
search_results %>% group_by(periodical) %>% 
  summarise(count=n(),total_IF=sum(impact_factor,na.rm = T)) %>% 
  filter(nchar(periodical)>0) %>%
  arrange(desc(count),desc(total_IF)) %>% 
  head(20) %>% 
  kable(caption = "《日报》中文献的来源期刊")
```




```{r eval=FALSE}
paper_words <- lapply(1:nrow(search_results),function(i){
  df <- search_results[i,c("uuid","content")]
  uuid <- df$uuid
  word_freq <- mrgut_word_freq(df$content,n=500)
  word_freq$uuid <- uuid
  return(word_freq)
})

total_words <- paper_words %>%
  group_by(uuid) %>% 
  summarize(total=sum(Freq))
```


```{r}
# 根据热心肠日报的词云和短科普人工阅读，得到关键词
keywords <- "TMAO|trimethylamine N-oxide|cardiovascular|CVD|atherosclerosis|coronary artery disease|coronary heart disease|Hypertension|high blood pressure"



M2 <- M %>% filter(str_detect(AB,toupper(keywords))) %>%
  filter(PY>2009)
```



在20年的数据中一共找到 `r nrow(M2)` 篇文献与“心血管”疾病相关，其中有 `r nrow(dplyr::filter(M2,HC==TRUE))` 篇高被引论文。


```{r fig.cap="心血管相关研究论文的增长趋势"}
# 全部文献主要作者
pos <- position_stack()
M2 %>%  group_by(PY,HC) %>%
  summarise(n=n()) %>%
  ggplot(aes(PY,n,fill=HC)) +
  geom_col(position = pos)  + 
  geom_text(aes(label=n),vjust=-.2,position = pos) +
  guides(fill=guide_legend(title = "是否高被引")) +
  theme(legend.position = "right")

```


```{r fig.cap="发文章数目最多的作者"}
# 全部文献主要作者
df <- M2 %>% mutate(author = strsplit(AF,";")) %>%
  unnest(author) %>% 
  mutate(author=trim(author)) %>%
  group_by(author,group) %>% 
  summarise(n=n()) 
top <- df %>% group_by(author) %>% summarise(total=sum(n)) %>% arrange(desc(total)) %>% head(30) %>% mutate(author=as_factor(author))
df %>% filter(author %in% top$author) %>% ungroup() %>%
  mutate(author=factor(author,levels=levels(top$author))) %>%
  ggplot(aes(author,n,fill=group)) +
  geom_col() +
  geom_text(aes(label=n),position = position_stack(0.5),size=2,color="white") +
  guides(fill=guide_legend(title="影响因子区间")) +
  theme(axis.text.x = element_text(angle = 60,vjust = 1,hjust = 1),
        legend.position = "right")


```

## 作者合作网络


知名的研究团队

```{r fig.width=10,fig.asp=1}
# 作者合作网络
net_matrix <- biblioNetwork(M2,analysis = "collaboration",network = "authors",sep=";")
net <- networkPlot(net_matrix,n=80,type = "kamada",Title = "作者合作网络",halo=T,edges.min=2,size=T,alpha=1)
```

## 国家、机构的数据展现

```{r}
M2 <- metaTagExtraction(M2, Field = "AU_CO", sep = ";")
M2$AU_CO_NR <- sapply(lapply(strsplit(M2$AU_CO,";"),unique),function(x)paste0(x,collapse=";"))
```

```{r}
country <- tableTag(M2,Tag = "AU_CO_NR",sep = ";")
data.frame(country,stringsAsFactors = F) %>% 
  mutate(country=as.character(Tab)) %>%
  mutate(country=ifelse(is.part_of_china(country),"CHINA",country)) %>%
  group_by(country) %>%
  summarise(count=sum(Freq)) %>% 
  arrange(desc(count)) %>% 
  head(10) %>%
  kable(caption = "不同国家的论文数量")
```


```{r fig.asp=1,fig.cap="国家间的合作"}
net_matrix <- biblioNetwork(M2, analysis = "collaboration",network = "countries",sep = ";")
net <- networkPlot(net_matrix,n=20,Title = "国家间的合作",type = "kamada",size = T,remove.multiple = F,remove.isolates = F)
```

```{r}
M2 <- metaTagExtraction(M2, Field = "AU_UN", sep = ";")
M2$AU_UN_NR <- sapply(lapply(strsplit(M2$AU_UN,";"),unique),function(x)paste0(x,collapse=";"))

```


```{r}
aff <- tableTag(M2,Tag = "AU_UN_NR",sep = ";")
data.frame(aff,stringsAsFactors = F) %>% 
  mutate(aff=as.character(Tab)) %>%
  group_by(aff) %>%
  summarise(count=sum(Freq)) %>% 
  arrange(desc(count)) %>% 
  head(20) %>%
  kable(caption = "不同机构的论文数量")
```


```{r fig.asp=1,fig.cap="机构间的合作"}
net_matrix <- biblioNetwork(M2, analysis = "collaboration",network = "universities",sep = ";")
net <- networkPlot(net_matrix,n=30,Title = "机构间的合作",type = "kamada",size = T,
                   # weighted = T,
                   remove.multiple = F,remove.isolates = F,halo = T)
```

## 看看有哪些中国学者

```{r}
M2 %>%
  filter(is.part_of_china(AU_CO_NR)) %>%
  tableTag(Tag = "AF") %>%
  as_tibble() %>%
  rename(Name="Tab",Records="n") %>%
  head(10) %>%
  kable()
```




## 重点关键词

本地被引次数（Local citation scores, LCS）是用来衡量文献在本地数据库中的引用次数的指标。与全局被引次数（Global citation score，GCS）相比，GCS对应的是WOS数据库中的全部对某一文献的引用次数，而LCS对应的是在本地的若干篇文献对某一文献的引用次数。在这里，本地文献是WOS数据库全部文献的一个子集，因此，LCS不会比GCS大，但是可以反映一批特定文献的集合中究竟那些文献更加重要。

```{r}
LC <- localCitations(M2)
# 关键词对应的文章数目
LC$M %>% mutate(keyword = strsplit(ID,";")) %>%
  unnest(keyword) %>% 
  mutate(keyword=trim(keyword)) %>%
  group_by(keyword) %>%
  summarise(total_record=length(unique(UT)),
            highly_cited=sum(HC),
            total_cited=sum(TC),
            local_cited=sum(LCS)) %>%
  arrange(desc(local_cited)) %>%
  head(50) %>%
  kable(caption = "重点关键词对应的文献数目和引用次数")
```

## 关键词共词网络

共词网络体现不同的词语在同一篇文献中出现的现象。同时出现的关键词之间有比较密切的关联。


```{r}
additional_stopword_CVD <- "MICE|PROFILES|ULCERATIVE-COLITIS|UNITED-STATES|VALIDATION|HELICOBACTER_PYLORI|INDUCTION|RATS|MICE"
nonsense_keyword <- paste0(search_keywords,additional_stopword_CVD,collapse = "|") %>% toupper()
```



```{r fig.width=10,fig.asp=1.2,fig.cap="关键词共现网络"}
net_matrix <- biblioNetwork(M2,analysis = "co-occurrences",network = "keywords",sep = ";")
selected <- !str_detect(colnames(net_matrix), nonsense_keyword)
net <- networkPlot(net_matrix[selected,selected],n=30,Title = "关键词共现网络",
                   type="kamada",size=T,halo=T,alpha=1,edges.min=5)

```



## 关键词趋势 （按照关键词比例）


```{r}
M2 <-  M %>% filter(str_detect(AB,toupper(keywords)))
df <- M2 %>% mutate(keyword = strsplit(ID,";")) %>%
  unnest(keyword) %>% 
  mutate(keyword=trim(keyword)) %>%
  filter(!str_detect(keyword,nonsense_keyword)) %>%
  group_by(keyword,PY) %>% 
  summarise(n=n()) %>%
  group_by(PY) %>%
  mutate(proportion=n/sum(n)) %>%
  # 有部分文章的 ID 为 NA（没有 ID）
  filter(!is.na(keyword)) %>%
  ungroup() %>%
  complete(PY,keyword,fill = list(n=0,proportion=0))

library(ggpubr)

# 将20年分为四个阶段
data <- df %>% mutate(stage=cut(PY,breaks = seq(from=2000,to=2020,by=5),
                         labels = c("First","Second","Third","Fourth"),
                         right = F)) %>%
  select(keyword,n,proportion,stage) 

# 去掉出现频次太少的关键词
data <- data %>% filter(keyword %in% (data %>% group_by(keyword) %>% summarise(total=sum(n)) %>% filter(total > 2) %>% pull(keyword))) %>%
  ungroup()

# 利用统计方法计算差异，得出变化显著的关键词
unique_ID <- unique(data$keyword)



stats_aov <- compare_means(proportion~stage, data, method = "aov",group.by = "keyword")

stats_aov <- stats_aov %>% filter(p.adj<1e-2) %>% arrange(p.adj)
```

按照我们的方法论，在 `r length(unique(data$keyword))` 不同的关键词中发现 `r nrow(stats_aov)` 个显著变化的关键词。

```{r}
subplot <- data.frame(keyword=stats_aov$keyword, subplot=rep(1:10,each=10)[1:nrow(stats_aov)])
df <- df %>% filter(keyword %in% stats_aov$keyword) %>% left_join(subplot) %>% ungroup() 

plots <- lapply(sort(unique(df$subplot)), function(sub){
  df %>% filter(subplot==sub) %>%
  mutate(PY=as.numeric(PY)) %>%
  ggplot(aes(PY,proportion,fill=keyword)) +
  geom_area() +
    coord_cartesian(xlim = c(2010,2020)) +
    scale_x_continuous(breaks = 2000:2020) +
  # geom_text(aes(x=I(2020),label=keyword),position = position_stack(0.5),size=2,color="white") +
  theme(legend.position = "right")
})
```


```{r fig.width=10,fig.cap="近二十年显著变化的WOS关键词"}
cowplot::plot_grid(plotlist = plots,ncol = 2,align = "hv")

```

## 关键词趋势（按照关键词数目）

```{r}
df <- M2 %>% mutate(keyword = strsplit(ID,";")) %>%
  unnest(keyword) %>% 
  mutate(keyword=trim(keyword)) %>%
  filter(!str_detect(keyword,nonsense_keyword)) %>%
  group_by(keyword,PY) %>% 
  summarise(n=n()) %>%
  group_by(PY) %>%
  mutate(proportion=n/sum(n)) %>%
  # 有部分文章的 ID 为 NA（没有 ID）
  filter(!is.na(keyword)) %>%
  ungroup() %>%
  complete(PY,keyword,fill = list(n=0,proportion=0))

library(ggpubr)

# 将20年分为四个阶段
data <- df %>% mutate(stage=cut(PY,breaks = seq(from=2000,to=2020,by=5),
                         labels = c("First","Second","Third","Fourth"),
                         right = F)) %>%
  select(keyword,n,proportion,stage) 

# 去掉出现频次太少的关键词
data <- data %>% filter(keyword %in% (data %>% group_by(keyword) %>% summarise(total=sum(n)) %>% filter(total > 2) %>% pull(keyword))) %>%
  ungroup()

# 利用统计方法计算差异，得出变化显著的关键词
unique_ID <- unique(data$keyword)



stats_aov <- compare_means(n~stage, data, method = "aov",group.by = "keyword")

stats_aov <- stats_aov %>% filter(p.adj<1e-2) %>% arrange(p.adj)
```
按照我们的方法论，在 `r length(unique(data$keyword))` 中发现 `r nrow(stats_aov)` 个显著变化的关键词。

```{r}
subplot <- data.frame(keyword=stats_aov$keyword, subplot=rep(1:100,each=10)[1:nrow(stats_aov)])
df <- df %>% filter(keyword %in% stats_aov$keyword) %>% left_join(subplot) %>% ungroup() 

plots <- lapply(sort(unique(df$subplot)), function(sub){
  df %>% filter(subplot==sub) %>%
    mutate(PY=as.numeric(PY)) %>%
    ggplot(aes(PY,n,fill=keyword)) +
    geom_area() +
    coord_cartesian(xlim = c(2010,2019)) +
    scale_x_continuous(breaks = 2000:2020) +
  # geom_text(aes(x=I(2020),label=keyword),position = position_stack(0.5),size=2,color="white") +
  theme(legend.position = "right")
})
```


```{r fig.width=10,fig.asp=1.2}
cowplot::plot_grid(plotlist = plots,ncol = 1,align = "hv")

```


